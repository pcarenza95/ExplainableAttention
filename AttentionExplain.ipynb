{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d362004-72c7-4aad-a56d-31d5e00d5211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Created directory: ./experiments/20250903_191527\n",
      "\n",
      "==================================================\n",
      "Running experiment 1/4: baseline\n",
      "==================================================\n",
      "Starting experiment: baseline\n",
      "Output directory: ./experiments/20250903_191527/baseline\n",
      "Created directory: ./experiments/20250903_191527/baseline\n",
      "Generating sorting dataset with sequence length 20...\n",
      "Model has 724,874 parameters\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:14<00:00, 17.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 1.6405 | Val Loss: 0.4717 | Val Accuracy: 0.8445 | Grad Norm: 2.9867 | LR: 0.000667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:14<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.4062 | Val Loss: 0.1454 | Val Accuracy: 0.9653 | Grad Norm: 5.5576 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:14<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.2570 | Val Loss: 0.1335 | Val Accuracy: 0.9512 | Grad Norm: 5.9799 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:14<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.1945 | Val Loss: 0.0631 | Val Accuracy: 0.9886 | Grad Norm: 5.4222 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:15<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.1585 | Val Loss: 0.0488 | Val Accuracy: 0.9900 | Grad Norm: 4.9270 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:19<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.1378 | Val Loss: 0.0303 | Val Accuracy: 0.9967 | Grad Norm: 4.3415 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:20<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.1297 | Val Loss: 0.0278 | Val Accuracy: 0.9966 | Grad Norm: 4.5416 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:21<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.1165 | Val Loss: 0.0272 | Val Accuracy: 0.9953 | Grad Norm: 4.2401 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:19<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.1037 | Val Loss: 0.0215 | Val Accuracy: 0.9970 | Grad Norm: 3.8751 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████████████████████████████████████████████████████████████████| 250/250 [00:19<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0933 | Val Loss: 0.0231 | Val Accuracy: 0.9949 | Grad Norm: 3.6912 | LR: 0.001000\n",
      "Visualizing attention patterns...\n",
      "Testing length generalization...\n",
      "Length: 20, Accuracy: 0.9955\n",
      "Length: 22, Accuracy: 0.6464\n",
      "Length: 25, Accuracy: 0.3484\n",
      "Length: 30, Accuracy: 0.2230\n",
      "Experiment completed! Results saved to ./experiments/20250903_191527/baseline\n",
      "\n",
      "==================================================\n",
      "Running experiment 2/4: rope\n",
      "==================================================\n",
      "Starting experiment: rope\n",
      "Output directory: ./experiments/20250903_191527/rope\n",
      "Created directory: ./experiments/20250903_191527/rope\n",
      "Generating sorting dataset with sequence length 20...\n",
      "Model has 200,586 parameters\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:20<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.9896 | Val Loss: 0.2901 | Val Accuracy: 0.9033 | Grad Norm: 4.4458 | LR: 0.000667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:20<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.3590 | Val Loss: 0.1576 | Val Accuracy: 0.9506 | Grad Norm: 7.4462 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:20<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.2732 | Val Loss: 0.1348 | Val Accuracy: 0.9577 | Grad Norm: 8.6026 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:22<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.2187 | Val Loss: 0.0703 | Val Accuracy: 0.9871 | Grad Norm: 7.2765 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:24<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.1850 | Val Loss: 0.0477 | Val Accuracy: 0.9936 | Grad Norm: 6.4653 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:24<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.1650 | Val Loss: 0.0576 | Val Accuracy: 0.9875 | Grad Norm: 6.5915 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:24<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.1503 | Val Loss: 0.0450 | Val Accuracy: 0.9894 | Grad Norm: 6.0703 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:21<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.1320 | Val Loss: 0.0501 | Val Accuracy: 0.9845 | Grad Norm: 5.6749 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:24<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.1264 | Val Loss: 0.1724 | Val Accuracy: 0.9188 | Grad Norm: 6.0963 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████████████████████████████████████████████████████████████████| 250/250 [00:20<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.1165 | Val Loss: 0.0265 | Val Accuracy: 0.9935 | Grad Norm: 5.9424 | LR: 0.001000\n",
      "Visualizing attention patterns...\n",
      "Testing length generalization...\n",
      "Length: 20, Accuracy: 0.9945\n",
      "Length: 22, Accuracy: 0.9100\n",
      "Length: 25, Accuracy: 0.7800\n",
      "Length: 30, Accuracy: 0.6197\n",
      "Experiment completed! Results saved to ./experiments/20250903_191527/rope\n",
      "\n",
      "==================================================\n",
      "Running experiment 3/4: alibi\n",
      "==================================================\n",
      "Starting experiment: alibi\n",
      "Output directory: ./experiments/20250903_191527/alibi\n",
      "Created directory: ./experiments/20250903_191527/alibi\n",
      "Generating sorting dataset with sequence length 20...\n",
      "Model has 200,586 parameters\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:20<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.8489 | Val Loss: 0.2741 | Val Accuracy: 0.9356 | Grad Norm: 4.6834 | LR: 0.000667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:20<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.3785 | Val Loss: 0.1691 | Val Accuracy: 0.9502 | Grad Norm: 7.2009 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:18<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.2975 | Val Loss: 0.1268 | Val Accuracy: 0.9699 | Grad Norm: 7.7801 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:16<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.2329 | Val Loss: 0.1046 | Val Accuracy: 0.9724 | Grad Norm: 6.2757 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:16<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.1904 | Val Loss: 0.0736 | Val Accuracy: 0.9858 | Grad Norm: 5.9633 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:24<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.1669 | Val Loss: 0.0554 | Val Accuracy: 0.9892 | Grad Norm: 5.7036 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:17<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.1563 | Val Loss: 0.0761 | Val Accuracy: 0.9752 | Grad Norm: 5.7439 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:16<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.1380 | Val Loss: 0.0525 | Val Accuracy: 0.9850 | Grad Norm: 5.0279 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:18<00:00, 13.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.1288 | Val Loss: 0.0602 | Val Accuracy: 0.9813 | Grad Norm: 4.6817 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████████████████████████████████████████████████████████████████| 250/250 [00:21<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.1214 | Val Loss: 0.0274 | Val Accuracy: 0.9965 | Grad Norm: 5.2100 | LR: 0.001000\n",
      "Visualizing attention patterns...\n",
      "Testing length generalization...\n",
      "Length: 20, Accuracy: 0.9990\n",
      "Length: 22, Accuracy: 0.6977\n",
      "Length: 25, Accuracy: 0.4184\n",
      "Length: 30, Accuracy: 0.2450\n",
      "Experiment completed! Results saved to ./experiments/20250903_191527/alibi\n",
      "\n",
      "==================================================\n",
      "Running experiment 4/4: longformer\n",
      "==================================================\n",
      "Starting experiment: longformer\n",
      "Output directory: ./experiments/20250903_191527/longformer\n",
      "Created directory: ./experiments/20250903_191527/longformer\n",
      "Generating sorting dataset with sequence length 20...\n",
      "Model has 724,874 parameters\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:17<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 1.6477 | Val Loss: 0.4469 | Val Accuracy: 0.8673 | Grad Norm: 2.9739 | LR: 0.000667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:16<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.4105 | Val Loss: 0.1580 | Val Accuracy: 0.9625 | Grad Norm: 5.5020 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:18<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.2722 | Val Loss: 0.1531 | Val Accuracy: 0.9371 | Grad Norm: 6.0405 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:17<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.2070 | Val Loss: 0.1014 | Val Accuracy: 0.9707 | Grad Norm: 5.2857 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:19<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.1688 | Val Loss: 0.0678 | Val Accuracy: 0.9823 | Grad Norm: 4.5516 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:16<00:00, 14.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.1476 | Val Loss: 0.0494 | Val Accuracy: 0.9891 | Grad Norm: 4.5069 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:16<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.1377 | Val Loss: 0.0386 | Val Accuracy: 0.9929 | Grad Norm: 4.9098 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:16<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.1196 | Val Loss: 0.0293 | Val Accuracy: 0.9958 | Grad Norm: 4.2416 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|█████████████████████████████████████████████████████████████████████| 250/250 [00:16<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.1099 | Val Loss: 0.0214 | Val Accuracy: 0.9967 | Grad Norm: 4.1396 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████████████████████████████████████████████████████████████████| 250/250 [00:18<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.1034 | Val Loss: 0.0247 | Val Accuracy: 0.9949 | Grad Norm: 4.2451 | LR: 0.001000\n",
      "Visualizing attention patterns...\n",
      "Testing length generalization...\n",
      "Length: 20, Accuracy: 0.9965\n",
      "Length: 22, Accuracy: 0.6332\n",
      "Length: 25, Accuracy: 0.3768\n",
      "Length: 30, Accuracy: 0.2073\n",
      "Experiment completed! Results saved to ./experiments/20250903_191527/longformer\n",
      "\n",
      "Generating comparative analysis...\n",
      "\n",
      "EXPERIMENT SUMMARY\n",
      "================================================================================\n",
      "Experiment    Task Attention Type Position Encoding  Best Val Accuracy  Training Time (s)  Parameters  Trained Length  Length 20 Acc  Length 22 Acc  Length 25 Acc  Length 30 Acc\n",
      "  baseline sorting           full           learned           0.996950         182.433403      724874              20         0.9955       0.646364         0.3484       0.223000\n",
      "      rope sorting           full              rope           0.993625         238.043910      200586              20         0.9945       0.910000         0.7800       0.619667\n",
      "     alibi sorting          alibi        sinusoidal           0.996500         200.389720      200586              20         0.9990       0.697727         0.4184       0.245000\n",
      "longformer sorting     longformer           learned           0.996725         183.279464      724874              20         0.9965       0.633182         0.3768       0.207333\n",
      "\n",
      "All experiments completed! Results saved to ./experiments/20250903_191527\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Set device configuration\n",
    "device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def make_dir(path):\n",
    "    \"\"\"Create directory if it doesn't exist\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Created directory: {path}\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# --- Positional Embeddings and Attention Variants ---\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    \"\"\"Sinusoidal positional embeddings as in the original Transformer paper\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, seq_len, device):\n",
    "        pos = torch.arange(seq_len, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "        i = torch.arange(self.dim, dtype=torch.float32, device=device)\n",
    "        freqs = 1 / (10000 ** (2 * (i // 2) / self.dim))\n",
    "        enc = pos * freqs\n",
    "        enc[:, 0::2] = torch.sin(enc[:, 0::2])\n",
    "        enc[:, 1::2] = torch.cos(enc[:, 1::2])\n",
    "        return enc.unsqueeze(0)\n",
    "\n",
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    \"\"\"Rotary Positional Embedding (RoPE) - https://arxiv.org/abs/2104.09864\"\"\"\n",
    "    def __init__(self, dim, base=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.base = base\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "    def forward(self, seq_len, device):\n",
    "        t = torch.arange(seq_len, device=device).type_as(self.inv_freq)\n",
    "        freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        return emb.unsqueeze(0).unsqueeze(0)  # [1, 1, seq_len, dim]\n",
    "\n",
    "def apply_rotary_pos_emb(x, freqs):\n",
    "    \"\"\"Apply rotary positional embedding to input tensor\"\"\"\n",
    "    # x shape: [batch_size, num_heads, seq_len, head_dim]\n",
    "    # freqs shape: [1, 1, seq_len, dim]\n",
    "    \n",
    "    # Extract the sequence length from x\n",
    "    seq_len = x.shape[-2]\n",
    "    \n",
    "    # Ensure freqs matches the sequence length of x\n",
    "    freqs = freqs[:, :, :seq_len, :]\n",
    "    \n",
    "    head_dim = x.shape[-1]\n",
    "    if freqs.shape[-1] != head_dim:\n",
    "        # If dimension doesn't match, we need to interpolate or truncate\n",
    "        # For simplicity, we'll take the first head_dim elements\n",
    "        freqs = freqs[..., :head_dim]\n",
    "    \n",
    "    # Reshape for rotary application - handle both even and odd dimensions\n",
    "    x_rot = x.float()\n",
    "    x1 = x_rot[..., 0::2]  # Even indices\n",
    "    x2 = x_rot[..., 1::2]  # Odd indices\n",
    "    \n",
    "    # Extract cosine and sine components for the relevant dimensions\n",
    "    cos = torch.cos(freqs)[..., 0::2]  # Take even indices for cos\n",
    "    sin = torch.sin(freqs)[..., 0::2]  # Take even indices for sin\n",
    "    \n",
    "    # Make sure dimensions match\n",
    "    if cos.shape[-1] != x1.shape[-1]:\n",
    "        # Truncate if necessary\n",
    "        min_dim = min(cos.shape[-1], x1.shape[-1])\n",
    "        cos = cos[..., :min_dim]\n",
    "        sin = sin[..., :min_dim]\n",
    "        x1 = x1[..., :min_dim]\n",
    "        x2 = x2[..., :min_dim]\n",
    "    \n",
    "    # Apply rotary transformation\n",
    "    rotated_x1 = x1 * cos - x2 * sin\n",
    "    rotated_x2 = x2 * cos + x1 * sin\n",
    "    \n",
    "    rotated_x = torch.zeros_like(x_rot)\n",
    "    rotated_x[..., 0::2] = rotated_x1\n",
    "    rotated_x[..., 1::2] = rotated_x2\n",
    "    \n",
    "    return rotated_x.type_as(x)\n",
    "\n",
    "class ALiBiBias(nn.Module):\n",
    "    \"\"\"ALiBi (Attention with Linear Biases) - https://arxiv.org/abs/2108.12409\"\"\"\n",
    "    def __init__(self, heads):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        slopes = torch.tensor(self._get_slopes(heads))\n",
    "        self.register_buffer(\"slopes\", slopes.view(1, heads, 1, 1))\n",
    "\n",
    "    def _get_slopes(self, n):\n",
    "        def get_slopes_power_of_2(n):\n",
    "            start = (2**(-2**-(math.log2(n)-3)))\n",
    "            return [start*(start**i) for i in range(n)]\n",
    "        \n",
    "        if math.log2(n).is_integer():\n",
    "            return get_slopes_power_of_2(n)\n",
    "        else:\n",
    "            closest_power_of_2 = 2 ** math.floor(math.log2(n))\n",
    "            return (get_slopes_power_of_2(closest_power_of_2) + \n",
    "                    self._get_slopes(2 * closest_power_of_2)[0::2][:n - closest_power_of_2])\n",
    "\n",
    "    def forward(self, seq_len, device):\n",
    "        # Create ALiBi bias matrix with proper dimensions [1, heads, seq_len, seq_len]\n",
    "        bias = torch.arange(seq_len, device=device).float()\n",
    "        bias = bias - torch.arange(seq_len, device=device).unsqueeze(1)\n",
    "        bias = torch.abs(bias)  # Distance matrix\n",
    "        bias = bias.unsqueeze(0).unsqueeze(0)  # [1, 1, seq_len, seq_len]\n",
    "        bias = bias * self.slopes  # Apply slopes per head\n",
    "        return -bias  # Negative because we want to bias against distant tokens\n",
    "\n",
    "# Multihead with support for ALiBi, RoPE, recurrence, and sparse (Longformer/Performer)\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-head attention with various positional encoding and attention variants\"\"\"\n",
    "    def __init__(self, dim, heads=4, pos_mode='learned', attn_type='full', memory_len=0, window_size=32):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.heads = heads\n",
    "        self.pos_mode = pos_mode\n",
    "        self.attn_type = attn_type\n",
    "        self.memory_len = memory_len\n",
    "        self.window_size = window_size\n",
    "        self.head_dim = dim // heads\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.to_out = nn.Linear(dim, dim)\n",
    "\n",
    "        # Initialize positional embeddings based on mode\n",
    "        if pos_mode == 'learned':\n",
    "            self.pos_emb = nn.Embedding(2048, dim)\n",
    "        elif pos_mode == 'sinusoidal':\n",
    "            self.pos_emb = SinusoidalPosEmb(dim)\n",
    "        elif pos_mode == 'rope':\n",
    "            self.rope = RotaryPositionalEmbedding(self.head_dim)\n",
    "        \n",
    "        # Initialize attention bias if using ALiBi\n",
    "        if attn_type == 'alibi':\n",
    "            self.alibi = ALiBiBias(heads)\n",
    "        else:\n",
    "            self.alibi = None\n",
    "\n",
    "        # Store window size for Longformer\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, x, mask=None, memory=None):\n",
    "        B, T, C = x.shape\n",
    "        H = self.heads\n",
    "        \n",
    "        # Apply query, key, value projections\n",
    "        qkv = self.to_qkv(x).reshape(B, T, 3, H, C // H).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # [B, H, T, D]\n",
    "\n",
    "        # Apply positional encodings\n",
    "        if self.pos_mode == 'rope':\n",
    "            freqs = self.rope(T, x.device)\n",
    "            q = apply_rotary_pos_emb(q, freqs)\n",
    "            k = apply_rotary_pos_emb(k, freqs)\n",
    "        elif self.pos_mode == 'learned':\n",
    "            # For learned positional embeddings, we need to create position indices\n",
    "            pos_indices = torch.arange(T, device=x.device).unsqueeze(0)  # [1, T]\n",
    "            pos_emb = self.pos_emb(pos_indices).reshape(1, T, H, C // H).permute(0, 2, 1, 3)\n",
    "            q = q + pos_emb\n",
    "            k = k + pos_emb\n",
    "        elif self.pos_mode == 'sinusoidal':\n",
    "            # For sinusoidal, use the SinusoidalPosEmb class\n",
    "            pos_emb = self.pos_emb(T, x.device).reshape(1, T, H, C // H).permute(0, 2, 1, 3)\n",
    "            q = q + pos_emb\n",
    "            k = k + pos_emb\n",
    "\n",
    "        # Handle memory (for recurrent transformers)\n",
    "        if memory is not None:\n",
    "            k_mem, v_mem = memory\n",
    "            k = torch.cat([k_mem, k], dim=2)\n",
    "            v = torch.cat([v_mem, v], dim=2)\n",
    "            mem_len = k_mem.shape[2]\n",
    "        else:\n",
    "            mem_len = 0\n",
    "\n",
    "        # Compute attention scores\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        if self.attn_type == 'longformer':\n",
    "            seq_len = attn_scores.size(-1)\n",
    "            \n",
    "            # Create band mask efficiently\n",
    "            band_mask = torch.ones(seq_len, seq_len, device=x.device, dtype=torch.bool)\n",
    "            \n",
    "            # Create band mask using broadcasting\n",
    "            i = torch.arange(seq_len, device=x.device)\n",
    "            j = torch.arange(seq_len, device=x.device)\n",
    "            \n",
    "            # Create mask for positions within window\n",
    "            distance = torch.abs(i[:, None] - j[None, :])\n",
    "            band_mask = distance <= (self.window_size // 2)\n",
    "            \n",
    "            # Convert to attention mask (0 for allowed, -inf for masked)\n",
    "            band_mask = band_mask.float()\n",
    "            band_mask = (1.0 - band_mask) * -1e9  # 0 for allowed, -inf for masked\n",
    "            \n",
    "            attn_scores = attn_scores + band_mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Apply ALiBi bias\n",
    "        elif self.attn_type == 'alibi' and self.alibi is not None:\n",
    "            # ALiBi bias should be applied to the attention scores\n",
    "            # The bias matrix should have shape [1, heads, T, T + mem_len]\n",
    "            alibi_bias = self.alibi(T + mem_len, x.device)\n",
    "            attn_scores = attn_scores + alibi_bias\n",
    "\n",
    "        \n",
    "        # Apply input mask if provided\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # Compute attention weights\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Apply attention dropout during training\n",
    "        if self.training:\n",
    "            attn_weights = F.dropout(attn_weights, p=0.1)\n",
    "\n",
    "        # Compute output\n",
    "        out = torch.matmul(attn_weights, v)\n",
    "        out = out.transpose(1, 2).reshape(B, T, C)\n",
    "        \n",
    "        # Return output and memory if needed\n",
    "        if memory is not None:\n",
    "            new_memory = (k[:, :, -self.memory_len:], v[:, :, -self.memory_len:])\n",
    "            return self.to_out(out), new_memory, attn_weights\n",
    "        \n",
    "        return self.to_out(out), attn_weights\n",
    "\n",
    "# Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"Standard transformer block with pre-normalization\"\"\"\n",
    "    def __init__(self, dim, heads=4, ff_mult=4, pos_mode='learned', \n",
    "                 attn_type='full', memory_len=0, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(dim, heads, pos_mode, attn_type, memory_len)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(dim, dim * ff_mult),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim * ff_mult, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None, memory=None):\n",
    "        # Self-attention with residual connection\n",
    "        if memory is not None:\n",
    "            attn_out, new_memory, attn_weights = self.attn(self.norm1(x), mask, memory)\n",
    "            x = x + self.dropout(attn_out)\n",
    "        else:\n",
    "            attn_out, attn_weights = self.attn(self.norm1(x), mask)\n",
    "            x = x + self.dropout(attn_out)\n",
    "            new_memory = None\n",
    "        \n",
    "        # Feed-forward with residual connection\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        \n",
    "        return x, new_memory, attn_weights\n",
    "\n",
    "# Transformer Model with optional recurrence/memory\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Transformer model with configurable architecture and attention mechanisms\"\"\"\n",
    "    def __init__(self, dim=64, depth=4, heads=4, pos_mode='learned', \n",
    "                 attn_type='full', memory_len=0, vocab_size=10, ff_mult=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.depth = depth\n",
    "        self.memory_len = memory_len\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.token_emb = nn.Embedding(vocab_size, dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(dim, heads, ff_mult, pos_mode, attn_type, memory_len, dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.to_logits = nn.Linear(dim, vocab_size)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x, mask=None, memory=None):\n",
    "        # Token embeddings\n",
    "        x = self.token_emb(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Initialize memory if not provided\n",
    "        if memory is None and self.memory_len > 0:\n",
    "            B, T = x.shape[0], x.shape[1]\n",
    "            memory = [\n",
    "                torch.zeros(B, self.blocks[0].attn.heads, self.memory_len, self.dim // self.blocks[0].attn.heads, \n",
    "                           device=x.device) for _ in range(self.depth)\n",
    "            ]\n",
    "        \n",
    "        # Process through transformer blocks\n",
    "        new_memory = [] if self.memory_len > 0 else None\n",
    "        attention_weights = []\n",
    "        for i, blk in enumerate(self.blocks):\n",
    "            if memory is not None:\n",
    "                x, mem, attn = blk(x, mask, memory[i] if memory is not None else None)\n",
    "                if new_memory is not None:\n",
    "                    new_memory.append(mem)\n",
    "                attention_weights.append(attn)\n",
    "            else:\n",
    "                x, _, attn = blk(x, mask)\n",
    "                attention_weights.append(attn)\n",
    "        \n",
    "        # Final normalization and output\n",
    "        x = self.norm(x)\n",
    "        logits = self.to_logits(x)\n",
    "        \n",
    "        return logits, new_memory, attention_weights\n",
    "\n",
    "# --- Algorithmic Task Datasets ---\n",
    "class AlgorithmicTaskDataset:\n",
    "    def __init__(self, task='sorting', seq_length=10, vocab_size=10, num_samples=10000):\n",
    "        self.task = task\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "    def generate_sorting_data(self):\n",
    "        data = []\n",
    "        targets = []\n",
    "        \n",
    "        for _ in range(self.num_samples):\n",
    "            # Generate random sequence\n",
    "            seq = np.random.randint(1, self.vocab_size, self.seq_length)\n",
    "            \n",
    "            # Target is the sorted sequence\n",
    "            target = np.sort(seq)\n",
    "            \n",
    "            data.append(seq)\n",
    "            targets.append(target)\n",
    "            \n",
    "        return np.array(data), np.array(targets)\n",
    "    \n",
    "    def generate_addition_data(self):\n",
    "        data = []\n",
    "        targets = []\n",
    "        \n",
    "        for _ in range(self.num_samples):\n",
    "            # Generate two numbers to add\n",
    "            num1 = np.random.randint(0, self.vocab_size // 2, self.seq_length // 2)\n",
    "            num2 = np.random.randint(0, self.vocab_size // 2, self.seq_length // 2)\n",
    "            \n",
    "            # Create input sequence: [num1, +, num2]\n",
    "            seq = np.concatenate([num1, [self.vocab_size - 1], num2])\n",
    "            \n",
    "            # Calculate target (sum)\n",
    "            total = np.sum(num1) + np.sum(num2)\n",
    "            # Represent as a sequence of digits\n",
    "            target_str = str(total)\n",
    "            target = np.array([int(d) for d in target_str] + [0] * (self.seq_length - len(target_str)))\n",
    "            \n",
    "            data.append(seq)\n",
    "            targets.append(target)\n",
    "            \n",
    "        return np.array(data), np.array(targets)\n",
    "    \n",
    "    def generate_data(self):\n",
    "        if self.task == 'sorting':\n",
    "            return self.generate_sorting_data()\n",
    "        elif self.task == 'addition':\n",
    "            return self.generate_addition_data()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task: {self.task}\")\n",
    "    \n",
    "    def get_dataset(self):\n",
    "        data, targets = self.generate_data()\n",
    "        return torch.tensor(data, dtype=torch.long), torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "# --- Training and Evaluation Functions ---\n",
    "def train_model(model, train_data, train_targets, val_data, val_targets, \n",
    "                epochs=10, batch_size=32, lr=0.001, device='cpu', warmup_epochs=3):\n",
    "    \"\"\"Train the transformer model on algorithmic tasks\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(train_data, train_targets)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    val_dataset = torch.utils.data.TensorDataset(val_data, val_targets)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    grad_norms = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Warm-up scheduler\n",
    "    warmup_scheduler = optim.lr_scheduler.LambdaLR(\n",
    "        optimizer, \n",
    "        lr_lambda=lambda epoch: min(1.0, (epoch + 1) / warmup_epochs)\n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        epoch_grad_norms = []\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output, _, _ = model(data)\n",
    "            \n",
    "            # Handle sequence length mismatch - truncate to the minimum length\n",
    "            seq_len = min(output.size(1), target.size(1))\n",
    "            output = output[:, :seq_len, :]  # [batch_size, seq_len, vocab_size]\n",
    "            target = target[:, :seq_len]     # [batch_size, seq_len]\n",
    "            \n",
    "            # Reshape for loss calculation\n",
    "            output = output.reshape(-1, output.size(-1))\n",
    "            target = target.reshape(-1)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Track gradient norms\n",
    "            total_norm = 0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    param_norm = p.grad.data.norm(2)\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** 0.5\n",
    "            epoch_grad_norms.append(total_norm)\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        avg_grad_norm = np.mean(epoch_grad_norms)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        grad_norms.append(avg_grad_norm)\n",
    "        \n",
    "        # Update learning rate (warmup for first few epochs)\n",
    "        if epoch < warmup_epochs:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output, _, _ = model(data)\n",
    "                \n",
    "                # Handle sequence length mismatch\n",
    "                seq_len = min(output.size(1), target.size(1))\n",
    "                output = output[:, :seq_len, :]\n",
    "                target = target[:, :seq_len]\n",
    "                \n",
    "                # Reshape for loss calculation\n",
    "                output_flat = output.reshape(-1, output.size(-1))\n",
    "                target_flat = target.reshape(-1)\n",
    "                \n",
    "                loss = criterion(output_flat, target_flat)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                predictions = torch.argmax(output, dim=-1)\n",
    "                all_predictions.extend(predictions.cpu().numpy().flatten())\n",
    "                all_targets.extend(target.cpu().numpy().flatten())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        accuracy = accuracy_score(all_targets, all_predictions)\n",
    "        val_accuracies.append(accuracy)\n",
    "        \n",
    "        # Update learning rate based on validation loss\n",
    "        if epoch >= warmup_epochs:\n",
    "            scheduler.step(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Accuracy: {accuracy:.4f} | Grad Norm: {avg_grad_norm:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    return train_losses, val_losses, val_accuracies, grad_norms, training_time\n",
    "\n",
    "def test_length_generalization(model, original_length, new_lengths, task='sorting', \n",
    "                              vocab_size=10, device='cpu'):\n",
    "    \"\"\"Test model generalization to longer sequences\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for length in new_lengths:\n",
    "        # Generate test data with new length\n",
    "        if task == 'sorting':\n",
    "            test_data = np.random.randint(1, vocab_size, (100, length))\n",
    "            test_targets = np.sort(test_data, axis=1)\n",
    "        elif task == 'addition':\n",
    "            test_data = []\n",
    "            test_targets = []\n",
    "            for _ in range(100):\n",
    "                num1 = np.random.randint(0, vocab_size // 2, length // 2)\n",
    "                num2 = np.random.randint(0, vocab_size // 2, length // 2)\n",
    "                seq = np.concatenate([num1, [vocab_size - 1], num2])\n",
    "                total = np.sum(num1) + np.sum(num2)\n",
    "                target_str = str(total)\n",
    "                # Make target the same length as input for consistency\n",
    "                target = np.array([int(d) for d in target_str] + [0] * (length - len(target_str)))\n",
    "                test_data.append(seq)\n",
    "                test_targets.append(target)\n",
    "            test_data = np.array(test_data)\n",
    "            test_targets = np.array(test_targets)\n",
    "        \n",
    "        test_data = torch.tensor(test_data, dtype=torch.long).to(device)\n",
    "        test_targets = torch.tensor(test_targets, dtype=torch.long).to(device)\n",
    "        \n",
    "        # Test the model\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Process in batches to avoid memory issues\n",
    "            batch_size = 32\n",
    "            for i in range(0, len(test_data), batch_size):\n",
    "                batch_data = test_data[i:i+batch_size]\n",
    "                batch_targets = test_targets[i:i+batch_size]\n",
    "                \n",
    "                output, _, _ = model(batch_data)\n",
    "                \n",
    "                # Handle sequence length mismatch\n",
    "                seq_len = min(output.size(1), batch_targets.size(1))\n",
    "                output = output[:, :seq_len, :]\n",
    "                batch_targets = batch_targets[:, :seq_len]\n",
    "                \n",
    "                predictions = torch.argmax(output, dim=-1)\n",
    "                \n",
    "                all_predictions.extend(predictions.cpu().numpy().flatten())\n",
    "                all_targets.extend(batch_targets.cpu().numpy().flatten())\n",
    "        \n",
    "        accuracy = accuracy_score(all_targets, all_predictions)\n",
    "        results[length] = accuracy\n",
    "        print(f\"Length: {length}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_attention(model, data_sample, task='sorting', out_dir='./', device='cpu'):\n",
    "    \"\"\"Visualize attention patterns for a sample\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output, _, attention_weights = model(data_sample.unsqueeze(0).to(device))\n",
    "    \n",
    "    # Plot attention weights for each layer and head\n",
    "    num_layers = len(attention_weights)\n",
    "    num_heads = attention_weights[0].size(1)  # [batch_size, num_heads, seq_len, seq_len]\n",
    "    \n",
    "    fig, axes = plt.subplots(num_layers, num_heads, figsize=(4*num_heads, 4*num_layers))\n",
    "    \n",
    "    if num_layers == 1:\n",
    "        axes = [axes]\n",
    "    if num_heads == 1:\n",
    "        for i in range(num_layers):\n",
    "            axes[i] = [axes[i]]\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        for head in range(num_heads):\n",
    "            attn_map = attention_weights[layer][0, head].cpu().numpy()\n",
    "            ax = axes[layer][head]\n",
    "            sns.heatmap(attn_map, ax=ax, cmap='viridis')\n",
    "            ax.set_title(f'Layer {layer+1}, Head {head+1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f'{task}_attention.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return attention_weights\n",
    "\n",
    "# --- Experiment Setup and Reporting ---\n",
    "def run_algorithmic_experiment(cfg, out_dir):\n",
    "    \"\"\"Run a complete algorithmic task experiment with given configuration\"\"\"\n",
    "    print(f\"Starting experiment: {cfg['name']}\")\n",
    "    print(f\"Output directory: {out_dir}\")\n",
    "    make_dir(out_dir)\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    set_seed(cfg.get('seed', 42))\n",
    "    \n",
    "    # Save configuration\n",
    "    with open(os.path.join(out_dir, 'config.json'), 'w') as f:\n",
    "        json.dump(cfg, f, indent=2)\n",
    "    \n",
    "    # Generate dataset\n",
    "    print(f\"Generating {cfg['task']} dataset with sequence length {cfg['seq_length']}...\")\n",
    "    dataset = AlgorithmicTaskDataset(\n",
    "        task=cfg['task'], \n",
    "        seq_length=cfg['seq_length'], \n",
    "        vocab_size=cfg['vocab_size'],\n",
    "        num_samples=10000\n",
    "    )\n",
    "    data, targets = dataset.get_dataset()\n",
    "    \n",
    "    # Split into train and validation\n",
    "    split_idx = int(0.8 * len(data))\n",
    "    train_data, val_data = data[:split_idx], data[split_idx:]\n",
    "    train_targets, val_targets = targets[:split_idx], targets[split_idx:]\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TransformerModel(\n",
    "        dim=cfg['dim'],\n",
    "        depth=cfg['depth'], \n",
    "        heads=cfg['heads'],\n",
    "        pos_mode=cfg['pos_mode'], \n",
    "        attn_type=cfg['attn_type'],\n",
    "        memory_len=cfg['memory_len'], \n",
    "        vocab_size=cfg['vocab_size'],\n",
    "        ff_mult=cfg.get('ff_mult', 4),\n",
    "        dropout=cfg.get('dropout', 0.1)\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    train_losses, val_losses, val_accuracies, grad_norms, training_time = train_model(\n",
    "        model, train_data, train_targets, val_data, val_targets,\n",
    "        epochs=cfg['epochs'], batch_size=cfg['batch_size'], lr=cfg['lr'], \n",
    "        device=device, warmup_epochs=cfg.get('warmup_epochs', 3)\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(grad_norms, label='Gradient Norm')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Norm')\n",
    "    plt.legend()\n",
    "    plt.title('Gradient Norms')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f\"{cfg['task']}_training_history.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualize attention for a sample\n",
    "    print(\"Visualizing attention patterns...\")\n",
    "    sample_idx = 0 \n",
    "    attention_weights = visualize_attention(\n",
    "        model, val_data[sample_idx], task=cfg['task'], out_dir=out_dir, device=device\n",
    "    )\n",
    "    \n",
    "    # Test length generalization\n",
    "    print(\"Testing length generalization...\")\n",
    "    new_lengths = [cfg['seq_length'], cfg['seq_length'] + 2, cfg['seq_length'] + 5, cfg['seq_length'] + 10]\n",
    "    generalization_results = test_length_generalization(\n",
    "        model, cfg['seq_length'], new_lengths, task=cfg['task'], \n",
    "        vocab_size=cfg['vocab_size'], device=device\n",
    "    )\n",
    "    \n",
    "    # Plot generalization results\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    lengths = list(generalization_results.keys())\n",
    "    accuracies = list(generalization_results.values())\n",
    "    \n",
    "    plt.bar(range(len(lengths)), accuracies, tick_label=lengths)\n",
    "    plt.xlabel('Sequence Length')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f\"Length Generalization on {cfg['task']} task\")\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    for i, acc in enumerate(accuracies):\n",
    "        plt.text(i, acc + 0.01, f'{acc:.2f}', ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f\"{cfg['task']}_generalization.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Generate performance report\n",
    "    report = {\n",
    "        \"training_summary\": {\n",
    "            \"final_train_loss\": train_losses[-1],\n",
    "            \"final_val_loss\": val_losses[-1],\n",
    "            \"final_val_accuracy\": val_accuracies[-1],\n",
    "            \"val_accuracies_history\": val_accuracies, \n",
    "            \"training_time\": training_time,\n",
    "            \"best_val_accuracy\": max(val_accuracies),\n",
    "            \"convergence_epoch\": val_accuracies.index(max(val_accuracies)) + 1,\n",
    "        },\n",
    "        \"generalization_results\": generalization_results,\n",
    "        \"model_architecture\": {\n",
    "            \"dimension\": cfg['dim'],\n",
    "            \"depth\": cfg['depth'],\n",
    "            \"heads\": cfg['heads'],\n",
    "            \"position_encoding\": cfg['pos_mode'],\n",
    "            \"attention_type\": cfg['attn_type'],\n",
    "            \"memory_length\": cfg['memory_len'],\n",
    "            \"vocabulary_size\": cfg['vocab_size'],\n",
    "            \"parameters_total\": sum(p.numel() for p in model.parameters()),\n",
    "        },\n",
    "        \"training_config\": cfg\n",
    "    }\n",
    "    \n",
    "    # Save report as JSON\n",
    "    with open(os.path.join(out_dir, 'performance_report.json'), 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    # Save as text summary\n",
    "    with open(os.path.join(out_dir, 'summary.txt'), 'w') as f:\n",
    "        f.write(\"ALGORITHMIC TASK EXPERIMENT REPORT\\n\")\n",
    "        f.write(\"==================================\\n\\n\")\n",
    "        f.write(f\"Experiment: {cfg['name']}\\n\")\n",
    "        f.write(f\"Task: {cfg['task']}\\n\")\n",
    "        f.write(f\"Training sequence length: {cfg['seq_length']}\\n\")\n",
    "        f.write(f\"Final training loss: {train_losses[-1]:.4f}\\n\")\n",
    "        f.write(f\"Final validation loss: {val_losses[-1]:.4f}\\n\")\n",
    "        f.write(f\"Final validation accuracy: {val_accuracies[-1]:.4f}\\n\")\n",
    "        f.write(f\"Best validation accuracy: {max(val_accuracies):.4f}\\n\")\n",
    "        f.write(f\"Training time: {training_time:.2f} seconds\\n\")\n",
    "        f.write(f\"Model parameters: {report['model_architecture']['parameters_total']:,}\\n\")\n",
    "        f.write(f\"Attention type: {cfg['attn_type']}\\n\")\n",
    "        f.write(f\"Position encoding: {cfg['pos_mode']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Length Generalization Results:\\n\")\n",
    "        for length, accuracy in generalization_results.items():\n",
    "            f.write(f\"  Length {length}: {accuracy:.4f}\\n\")\n",
    "    \n",
    "    # Save model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': cfg,\n",
    "        'history': {\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'val_accuracies': val_accuracies,\n",
    "            'grad_norms': grad_norms,\n",
    "        }\n",
    "    }, os.path.join(out_dir, 'model.pth'))\n",
    "    \n",
    "    print(f\"Experiment completed! Results saved to {out_dir}\")\n",
    "    return report\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Create output directory\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base_out_dir = f\"./experiments/{timestamp}\"\n",
    "    make_dir(base_out_dir)\n",
    "\n",
    "\n",
    "    NUM_EPOCHS = 10\n",
    "    TASK = 'sorting' # 'sorting' or 'addition'\n",
    "    SEQ_LENGTH = 20\n",
    "    # Define experiment configurations\n",
    "    experiments = [\n",
    "        {\n",
    "            'name': 'baseline',\n",
    "            'task': TASK,\n",
    "            'seq_length': SEQ_LENGTH,\n",
    "            'vocab_size': 10,\n",
    "            'dim': 64,\n",
    "            'depth': 4,\n",
    "            'heads': 4,\n",
    "            'pos_mode': 'learned',\n",
    "            'attn_type': 'full',\n",
    "            'memory_len': 0,\n",
    "            'epochs': NUM_EPOCHS,\n",
    "            'batch_size': 32,\n",
    "            'lr': 0.001,\n",
    "            'seed': 42\n",
    "        },\n",
    "        {\n",
    "            'name': 'rope',\n",
    "            'task': TASK,\n",
    "            'seq_length': SEQ_LENGTH,\n",
    "            'vocab_size': 10,\n",
    "            'dim': 64,\n",
    "            'depth': 4,\n",
    "            'heads': 4,\n",
    "            'pos_mode': 'rope',\n",
    "            'attn_type': 'full',\n",
    "            'memory_len': 0,\n",
    "            'epochs': NUM_EPOCHS,\n",
    "            'batch_size': 32,\n",
    "            'lr': 0.001,\n",
    "            'seed': 42\n",
    "        },\n",
    "        {\n",
    "            'name': 'alibi',\n",
    "            'task': TASK,\n",
    "            'seq_length': SEQ_LENGTH,\n",
    "            'vocab_size': 10,\n",
    "            'dim': 64,\n",
    "            'depth': 4,\n",
    "            'heads': 4,\n",
    "            'pos_mode': 'sinusoidal',\n",
    "            'attn_type': 'alibi',\n",
    "            'memory_len': 0,\n",
    "            'epochs': NUM_EPOCHS,\n",
    "            'batch_size': 32,\n",
    "            'lr': 0.001,\n",
    "            'seed': 42\n",
    "        },\n",
    "        {\n",
    "            'name': 'longformer',\n",
    "            'task': TASK,\n",
    "            'seq_length': SEQ_LENGTH,\n",
    "            'vocab_size': 10,\n",
    "            'dim': 64,\n",
    "            'depth': 4,\n",
    "            'heads': 4,\n",
    "            'pos_mode': 'learned',\n",
    "            'attn_type': 'longformer',\n",
    "            'memory_len': 0,\n",
    "            'window_size': 5,\n",
    "            'epochs': NUM_EPOCHS,\n",
    "            'batch_size': 32,\n",
    "            'lr': 0.001,\n",
    "            'seed': 42\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    # Run each experiment\n",
    "    for i, cfg in enumerate(experiments):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Running experiment {i+1}/{len(experiments)}: {cfg['name']}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        out_dir = os.path.join(base_out_dir, cfg['name'])\n",
    "        result = run_algorithmic_experiment(cfg, out_dir)\n",
    "        all_results[cfg['name']] = result\n",
    "        \n",
    "        # Clear GPU memory between experiments\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Generate comparative analysis\n",
    "    print(\"\\nGenerating comparative analysis...\")\n",
    "    \n",
    "    # Compare generalization across experiments\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for exp_name, result in all_results.items():\n",
    "        gen_results = result['generalization_results']\n",
    "        lengths = list(gen_results.keys())\n",
    "        accuracies = list(gen_results.values())\n",
    "        \n",
    "        plt.plot(lengths, accuracies, marker='o', label=exp_name, linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Sequence Length')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Length Generalization Comparison Across Models')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(base_out_dir, 'comparative_generalization.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_data = []\n",
    "    for exp_name, result in all_results.items():\n",
    "        summary_data.append({\n",
    "            'Experiment': exp_name,\n",
    "            'Task': result['training_config']['task'],\n",
    "            'Attention Type': result['training_config']['attn_type'],\n",
    "            'Position Encoding': result['training_config']['pos_mode'],\n",
    "            'Best Val Accuracy': result['training_summary']['best_val_accuracy'],\n",
    "            'Training Time (s)': result['training_summary']['training_time'],\n",
    "            'Parameters': result['model_architecture']['parameters_total'],\n",
    "            'Trained Length': result['training_config']['seq_length'],\n",
    "            **{f'Length {l} Acc': acc for l, acc in result['generalization_results'].items()}\n",
    "        })\n",
    "    \n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    df_summary.to_csv(os.path.join(base_out_dir, 'experiment_summary.csv'), index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nEXPERIMENT SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df_summary.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nAll experiments completed! Results saved to {base_out_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
